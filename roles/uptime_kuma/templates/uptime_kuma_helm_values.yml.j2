useDeploy: {{ uptime_kuma_deployment_type == 'deployment' }}

{% if uptime_kuma_service_account_create %}
serviceAccount:
  create: {{ uptime_kuma_service_account_create }}
  annotations: {{ uptime_kuma_service_account_annotations }}
  name: "{{ uptime_kuma_service_account_name }}"
{% endif %}

podAnnotations: {{ uptime_kuma_pod_annotations }}
podLabels: {{ uptime_kuma_pod_labels }}

podEnv: {{ uptime_kuma_pod_env }}

podSecurityContext: {{ uptime_kuma_pod_security_context }}

securityContext: {{ uptime_kuma_security_context }}

ingress:
  enabled: {{ uptime_kuma_ingress_enabled }}
{% if uptime_kuma_ingress_enabled %}
  className: "{{ uptime_kuma_ingress_classname }}"
  extraLabels: {{ uptime_kuma_ingress_labels }}
  hosts:
    - host: "{{ uptime_kuma_ingress_hostname }}"
      paths:
        - path: /
          pathType: ImplementationSpecific
  annotations:
    {{ uptime_kuma_ingress_annotations | ansible.builtin.to_nice_yaml | indent(4) }}
{% if uptime_kuma_ingress_tls_enabled %}
    cert-manager.io/cluster-issuer: "{{ uptime_kuma_ingress_certmanager_cluster_issuer }}"
  tls:
    - secretName: {{ uptime_kuma_ingress_tls_secret_name }}
      hosts:
        - {{ uptime_kuma_ingress_hostname }}
{% endif %}
{% endif %}

resources: {{ uptime_kuma_resources }}

nodeSelector: {}

tolerations: []

affinity: {}

{% if uptime_kuma_liveness_probe_enabled %}
livenessProbe:
  enabled: {{ uptime_kuma_liveness_probe_enabled }}
  failureThreshold: 3
  # Uptime-Kuma recommends to configure a delay of 180 seconds until the server fully started.
  # https://github.com/louislam/uptime-kuma/blob/ae224f9e188b1fc32ed8729818710975589cdce7/extra/healthcheck.go#L3
  initialDelaySeconds: 180
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 2
  # The NodeJS Version of this Healthcheck is no longer supported, therefore we don't specify a node command.
  # https://github.com/louislam/uptime-kuma/blob/ae224f9e188b1fc32ed8729818710975589cdce7/extra/healthcheck.js#L6
  exec:
    command:
      - "extra/healthcheck"
{% endif %}

{% if uptime_kuma_readiness_probe_enabled %}
readinessProbe:
  enabled: {{ uptime_kuma_readiness_probe_enabled }}
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 1
  failureThreshold: 3
  successThreshold: 1
  exec:
    command: []
  httpGet:
    path: /
    port: 3001
    scheme: HTTP
    httpHeaders: []
{% endif %}

volume:
  enabled: {{ uptime_kuma_volume_enabled }}
  accessMode: "{{ uptime_kuma_volume_access_mode }}"
  size: "{{ uptime_kuma_volume_size }}"
  existingClaim: "{{ uptime_kuma_volume_existing_claim }}"

strategy:
  type: Recreate

{% if uptime_kuma_mariadb_enabled %}
mariadb:
  enabled: {{ uptime_kuma_mariadb_enabled }}
  architecture: standalone
  auth:
    database: uptime_kuma
    username: uptime_kuma
    password: ""
    rootPassword: ""
{% endif %}

# Prometheus ServiceMonitor configuration
serviceMonitor:
  enabled: false
  # -- Scrape interval. If not set, the Prometheus default scrape interval is used.
  interval: 60s
  # -- Timeout if metrics can't be retrieved in given time interval
  scrapeTimeout: 10s
  # -- Scheme to use when scraping, e.g. http (default) or https.
  scheme: ~
  # -- TLS configuration to use when scraping, only applicable for scheme https.
  tlsConfig: {}
  # -- Prometheus [RelabelConfigs] to apply to samples before scraping
  relabelings: []
  # -- Prometheus [MetricRelabelConfigs] to apply to samples before ingestion
  metricRelabelings: []
  # -- Prometheus ServiceMonitor selector, only select Prometheus's with these
  # labels (if not set, select any Prometheus)
  selector: {}

  # -- Namespace where the ServiceMonitor resource should be created, default is
  # the same as the release namespace
  namespace: ~
  # -- Additional labels to add to the ServiceMonitor
  additionalLabels: {}
  # -- Additional annotations to add to the ServiceMonitor
  annotations: {}

  # -- BasicAuth credentials for scraping metrics, use API token and any string for username
  # basicAuth:
  #   username: "metrics"
  #   password: ""

# -- Use this option to set a custom DNS policy to the created deployment
dnsPolicy: ""

# -- Use this option to set custom DNS configurations to the created deployment
dnsConfig: {}

# -- Use this option to set custom PriorityClass to the created deployment
# ref: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass
priorityClassName: ""

# -- Create a NetworkPolicy
networkPolicy:
  # -- Enable/disable Network Policy
  enabled: false
  # -- Enable/disable Ingress policy type
  ingress: true
  # -- Enable/disable Egress policy type
  egress: true
  # -- Allow incoming connections only from specific Pods
  # When set to true, the geoserver will accept connections from any source.
  allowExternal: true
  # -- Selects particular namespaces for which all Pods are allowed as ingress sources
  namespaceSelector: {}
  #  matchLabels:
  #    role: frontend
  #  matchExpressions:
  #   - {key: role, operator: In, values: [frontend]}
